{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codex.codex as codex\n",
    "\n",
    "# requirements\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(fp):\n",
    "    with open(fp) as f:\n",
    "        j = json.load(f)\n",
    "    return j\n",
    "\n",
    "\n",
    "def cc_results_t(set_name, coverage: dict, element: str, strengths):\n",
    "    print(coverage.keys())\n",
    "    for t in strengths:\n",
    "        print(\n",
    "            \"{} | {} for {}-way interactions: {}\".format(\n",
    "                set_name, element, t, coverage[t][element]\n",
    "            )\n",
    "        )\n",
    "        if t == 3:\n",
    "            print()\n",
    "\n",
    "    return  # [coverage[t][element] for t in strengths]\n",
    "\n",
    "\n",
    "def sdcc_results_t(set_name, coverage: dict, element: str, strengths, direction):\n",
    "    print(coverage.keys())\n",
    "    for t in strengths:\n",
    "        print(\n",
    "            \"{} {} over {}-way interactions: {}\".format(\n",
    "                set_name, element, t, coverage[t][direction][\"SDCC\"]\n",
    "            )\n",
    "        )\n",
    "        if t == 3:\n",
    "            print()\n",
    "\n",
    "    return  # [coverage[t][direction]['SDCC'] for t in strengths]\n",
    "\n",
    "\n",
    "def display_input_file(filepath):\n",
    "    with open(filepath) as f:\n",
    "        input_template = json.load(f)\n",
    "    input_template = codex.output.output_json_readable(input_template, print_json=True)\n",
    "\n",
    "\n",
    "def describe_tabular_dataset(filepath):\n",
    "    abstract_df = pd.read_csv(filepath).drop(\"Unnamed: 0\", axis=1)\n",
    "    display(abstract_df)\n",
    "    display(abstract_df.describe())\n",
    "    for col_name in abstract_df.columns.tolist():\n",
    "        display(col_name, abstract_df[col_name].describe())\n",
    "\n",
    "\n",
    "def display_binning_file(filepath):\n",
    "    with open(filepath) as f:\n",
    "        print(f.read())\n",
    "\n",
    "\n",
    "def display_split_file(filepath):\n",
    "    splits_ab = load_json(filepath)\n",
    "    display(list(splits_ab.keys()))\n",
    "    display(codex.output.output_json_readable(splits_ab, truncate_lists=True))\n",
    "\n",
    "\n",
    "def model_performance(\n",
    "    train_name,\n",
    "    test_name,\n",
    "    train_input,\n",
    "    test_input,\n",
    "    train_coverage,\n",
    "    test_coverage,\n",
    "    metric=\"precision\",\n",
    "):\n",
    "    print(\"Obtaining model evaluations for a model trained on {}...\".format(train_name))\n",
    "    perf = load_json(\n",
    "        os.path.join(\"rareplanes_demo/performance\", train_input[\"performance_file\"])\n",
    "    )\n",
    "    print(\n",
    "        \"Performance of model trained on {} (CC_2: {}) and evaluated on {} (CC_2: {}):\".format(\n",
    "            train_name,\n",
    "            round(train_coverage[2][\"CC\"], 3),\n",
    "            test_name,\n",
    "            round(test_coverage[2][\"CC\"], 3),\n",
    "        )\n",
    "    )\n",
    "    codex.output.output_json_readable(\n",
    "        perf[\"test\"][\"Overall Performance\"], print_json=True\n",
    "    )\n",
    "\n",
    "    return perf[\"test\"][\"Overall Performance\"][metric]\n",
    "\n",
    "\n",
    "def model_performance_sdcc(train_name, test_name, train_input, metric=\"precision\"):\n",
    "    direction = test_name + \"-\" + train_name\n",
    "    print(\n",
    "        \"Obtaining model evaluations for a model trained on {} and evaluated on {}...\".format(\n",
    "            train_name, test_name\n",
    "        )\n",
    "    )\n",
    "    perf = load_json(\n",
    "        os.path.join(\"rareplanes_demo\", \"performance\", train_input[\"performance_file\"])\n",
    "    )\n",
    "\n",
    "    codex.output.output_json_readable(\n",
    "        perf[\"test\"][\"Overall Performance\"], print_json=True\n",
    "    )\n",
    "\n",
    "    return perf[\"test\"][\"Overall Performance\"][metric]\n",
    "\n",
    "\n",
    "def visualize_cc(codex_input):\n",
    "    output_path, strengths = codex.input_handler.define_experiment_variables(\n",
    "        codex_input\n",
    "    )\n",
    "    fig, ax = plt.subplots(2, 3, figsize=(16, 12))\n",
    "    fig.subplots_adjust(wspace=0.15, hspace=-0.5)\n",
    "\n",
    "    for i in range(len(ax)):\n",
    "        for j in range(len(ax[0])):\n",
    "            ax[i][j].axis(\"off\")\n",
    "\n",
    "    for t in strengths:\n",
    "        img_t = mpimg.imread(\n",
    "            os.path.join(\n",
    "                output_path, \"CC\", \"CC_binary-t{}_RarePlanes_all.png\".format(t)\n",
    "            )\n",
    "        )\n",
    "        img_t_op = mpimg.imread(\n",
    "            os.path.join(\n",
    "                output_path,\n",
    "                \"CC\",\n",
    "                \"CC_frequency_proportion_standardized-t{}_RarePlanes_all.png\".format(t),\n",
    "            )\n",
    "        )\n",
    "        ax[0][t - 1].imshow(img_t)\n",
    "        ax[1][t - 1].imshow(img_t_op)\n",
    "        \"\"\"ax[0].axis('off')\n",
    "        ax[1].axis('off')\"\"\"\n",
    "\n",
    "\n",
    "def visualize_sdcc(codex_input):\n",
    "    output_path, strengths = codex.input_handler.define_experiment_variables(\n",
    "        codex_input\n",
    "    )\n",
    "    fig, ax = plt.subplots(2, 3, figsize=(20, 16))\n",
    "    fig.subplots_adjust(wspace=0.15, hspace=-0.5)\n",
    "\n",
    "    target_name = codex_input[\"target_name\"]\n",
    "    source_name = codex_input[\"source_name\"]\n",
    "\n",
    "    for i in range(len(ax)):\n",
    "        for j in range(len(ax[0])):\n",
    "            ax[i][j].axis(\"off\")\n",
    "\n",
    "    for t in strengths:\n",
    "        img_t = mpimg.imread(\n",
    "            os.path.join(\n",
    "                output_path,\n",
    "                \"SDCC\",\n",
    "                \"SDCC-t{}-way Set Diff {} not appearing in {}_RarePlanes_wneither.png\".format(\n",
    "                    t, target_name, source_name\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "        img_t_op = mpimg.imread(\n",
    "            os.path.join(\n",
    "                output_path,\n",
    "                \"SDCC\",\n",
    "                \"SDCC-t{}-way Set Diff {} not appearing in {}_RarePlanes_wneither.png\".format(\n",
    "                    t, source_name, target_name\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "        ax[0][t - 1].imshow(img_t)\n",
    "        ax[1][t - 1].imshow(img_t_op)\n",
    "        \"\"\"ax[0].axis('off')\n",
    "        ax[1].axis('off')\"\"\"\n",
    "\n",
    "\n",
    "def split_intersection(list1, list2):\n",
    "    intersect = list(set(list1) & set(list2))\n",
    "    intersect = [entry for entry in intersect if entry != \"...\"]\n",
    "\n",
    "    print(\"The intersection of the splits contain {} entries.\".format(len(intersect)))\n",
    "    return intersect\n",
    "\n",
    "\n",
    "def differential_performance_cc(\n",
    "    train_cc_1, train_cc_2, perf_metric1, perf_metric2, metric, t\n",
    "):\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    plt.title(\"Combinatorial coverage against model performance\")\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0.5, 1)\n",
    "    plt.xlabel(\"Combinatorial coverage of training set for 2-way interactions\")\n",
    "    plt.ylabel(\"Model performance evaluating on test12: {}\".format(metric))\n",
    "    plt.grid(visible=\"on\")\n",
    "\n",
    "    plt.scatter(x=train_cc_1[t][\"CC\"], y=perf_metric1, color=\"red\")\n",
    "    plt.scatter(x=train_cc_2[t][\"CC\"], y=perf_metric2, color=\"green\")\n",
    "\n",
    "    plt.legend([\"train1\", \"train2\"])\n",
    "\n",
    "\n",
    "def differential_performance_sdcc(\n",
    "    train_cc_in,\n",
    "    train_cc_out,\n",
    "    direction_in,\n",
    "    direction_out,\n",
    "    perf_metric_in,\n",
    "    perf_metric_out,\n",
    "    metric,\n",
    "    t,\n",
    "):\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    plt.title(\"SDCC against model performance\")\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0.0, 1)\n",
    "    plt.xlabel(\"SDCC of training set for 2-way interactions: test-train\")\n",
    "    plt.ylabel(\"Model performance evaluating on test: {}\".format(metric))\n",
    "    plt.grid(visible=\"on\")\n",
    "\n",
    "    plt.scatter(x=train_cc_in[t][direction_in][\"SDCC\"], y=perf_metric_in, color=\"red\")\n",
    "    plt.scatter(\n",
    "        x=train_cc_out[t][direction_out][\"SDCC\"], y=perf_metric_out, color=\"green\"\n",
    "    )\n",
    "\n",
    "    plt.legend([\"train1\", \"train2\"])\n",
    "\n",
    "\n",
    "def display_sie_train_set(input_sie, feature, value):\n",
    "    #'Hour_of_Day', '[10.26,11.27)'\n",
    "\n",
    "    output_path, strengths = codex.input_handler.define_experiment_variables(input_sie)\n",
    "    split_by_csv_dir = os.path.join(output_path, \"splits_by_csv\")\n",
    "\n",
    "    covered_hour_0_train = pd.read_csv(\n",
    "        os.path.join(split_by_csv_dir, \"train_0_0_.csv\")\n",
    "    ).drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "    display(\"TRAINING SET EXCLUDING Hour_of_Day: [10.26,11.27)\")\n",
    "    display(covered_hour_0_train.head())\n",
    "\n",
    "    display(\"TRAINING SET Hour_of_Day: [10.26,11.27) SAMPLES:\")\n",
    "    display(\n",
    "        covered_hour_0_train[\n",
    "            covered_hour_0_train[\"Hour_of_Day\"] == \"[10.26,11.27)\"\n",
    "        ].head()\n",
    "    )\n",
    "\n",
    "    display(\"No samples with 'Hour_of_Day', '[10.26,11.27)'.\")\n",
    "\n",
    "\n",
    "def display_sie_test_sets(input_sie, feature, value):\n",
    "    output_path, strengths = codex.input_handler.define_experiment_variables(input_sie)\n",
    "    split_by_csv_dir = os.path.join(output_path, \"splits_by_csv\")\n",
    "\n",
    "    covered_hour_0_test_excl = pd.read_csv(\n",
    "        os.path.join(split_by_csv_dir, \"notcovered_0_0_.csv\")\n",
    "    ).drop(\"Unnamed: 0\", axis=1)\n",
    "    covered_hour_0_test_incl = pd.read_csv(\n",
    "        os.path.join(split_by_csv_dir, \"covered_0_0_.csv\")\n",
    "    ).drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "    display(\"TEST COVERED BY TRAINING SET (EXCLUDING Hour_of_Day: [10.26,11.27)):\")\n",
    "    display(covered_hour_0_test_incl.head())\n",
    "\n",
    "    display(\n",
    "        \"TEST NOT COVERED BY TRAINING SET (ALL SAMPLES' Hour_of_Day: [10.26,11.27)):\"\n",
    "    )\n",
    "    display(covered_hour_0_test_excl.head())\n",
    "\n",
    "\n",
    "def display_sie_results(input_sie, metric):\n",
    "    performance_path = os.path.join(\n",
    "        input_sie[\"codex_directory\"], input_sie[\"performance_folder\"]\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(3, 1, figsize=(20, 16))\n",
    "    for i in range(len(ax)):\n",
    "        ax[i].axis(\"off\")\n",
    "    img = mpimg.imread(os.path.join(performance_path, \"output_{}.png\".format(metric)))\n",
    "    img1 = mpimg.imread(os.path.join(performance_path, \"output_spread.png\"))\n",
    "    img2 = mpimg.imread(os.path.join(performance_path, \"output_incl_training.png\"))\n",
    "    ax[0].imshow(img)\n",
    "    ax[1].imshow(img1)\n",
    "    ax[2].imshow(img2)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0) CODEX directory\n",
    "To run its experiments, CODEX utilizes a CODEX directory in which datasets, binning files, split files, performance files, experiment folders, and input files which specify these elements, reside.\n",
    "\n",
    "CODEX can get a user started with a setup function, which can include template files for how each requirement should be formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "codex_directory_name = input(\"Name of CODEX directory:\")\n",
    "codex_directory = codex.setup_new_codex_env(\n",
    "    codex_directory_name, include_templates=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_input_file(os.path.join(codex_directory, 'configs', 'input_TEMPLATE.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabular dataset\n",
    "# describe_tabular_dataset(os.path.join(codex_directory, 'data', 'dataset_sample_abstract.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binning file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_binning_file(os.path.join(codex_directory, 'binning', 'bins_sample_abstract.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Dataset Evaluation\n",
    "CODEX's most basic, mode, \"dataset evaluation,\" computes combinatorial coverage for each specified $t$.\n",
    "\n",
    "*\"How complete is my dataset for a defined universe?\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RarePlanes Dataset)\n",
    "\n",
    "RarePlanes is an open source dataset by CosmiqWorks consisting of real and synthetic satellite images. In the real portion of the dataset, 253 distributed into 8,525 image tiles.\n",
    "\n",
    "Observe one such tile:\n",
    "\n",
    "The dataset also contains an associated metadata table, containing coordinates, weather, season, etc., for each tile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RarePlanes: Sample and its metadata\n",
    "from PIL import Image\n",
    "\n",
    "img_98_104001000F15D300_tile_177 = Image.open(\n",
    "    os.path.join(\"../resources/98_104001000F15D300_tile_177.png\")\n",
    ")\n",
    "rareplanes_df = pd.read_csv(\n",
    "    os.path.join(\n",
    "        \"rareplanes_demo\",\n",
    "        \"metadata\",\n",
    "        \"RarePlanes_Metadata_Augmented_Processed_localized-tiled-controlpt-d01-full_resampled.csv\",\n",
    "    )\n",
    ")\n",
    "rareplanes_df.index = rareplanes_df.image_tile_id\n",
    "display(img_98_104001000F15D300_tile_177)\n",
    "display(rareplanes_df.loc[\"98_104001000F15D300_tile_177\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a) Combinatorial coverage over a defined universe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "rareplanes_df.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning file, binned dataset\n",
    "display_binning_file(os.path.join(\"rareplanes_demo\", \"binning\", \"bins-signif.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cc_train1 = load_json(\n",
    "    os.path.join(\"rareplanes_demo\", \"configs\", \"cc_train1.json\")\n",
    ")\n",
    "universe, rareplanes_df_binned = codex.universe_handler.define_input_space(\n",
    "    input_cc_train1\n",
    ")\n",
    "\n",
    "# rareplanes_df_binned = pd.read_csv(os.path.join('rareplanes_demo', 'metadata', 'RarePlanes_Metadata_Augmented_Processed_localized-tiled-controlpt-d01-full_resampled_Binned.csv'))\n",
    "display(rareplanes_df_binned.head())\n",
    "display(universe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file\n",
    "input_cc_train1 = load_json(\n",
    "    os.path.join(\"rareplanes_demo\", \"configs\", \"cc_train1.json\")\n",
    ")\n",
    "display(codex.output.output_json_readable(input_cc_train1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b) Run dataset evaluation on different datasets\n",
    "From the overall dataset:\n",
    "- Withhold a randomly sampled test set from the RarePlanes overall dataset first\n",
    "    - Size: 215 samples\n",
    "- Construct a training set with artificially low coverage, train1\n",
    "    - By including only samples captured in \"Temperate Grasslands, Savannas & Shrublands\" biomes\n",
    "    - Size: 1,217 samples\n",
    "- Construct a training set with moderate coverage by randomly sampling from remaining samples, train2\n",
    "    - Size: 1,217 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CODEX\n",
    "train1_coverage = codex.run(input_cc_train1, verbose=\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON results: combinatorial coverage: __demo__/rareplanes_demo/demo_1-coverage_train1/coverage.json\n",
    "display(train1_coverage)\n",
    "train1_cc = cc_results_t(\"Train 1\", train1_coverage, \"CC\", [1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON results: missing interactions: __demo__/rareplanes_demo/demo_1-coverage_train1/coverage.json\n",
    "# TRY other result contents: ['count appearing interactions', 'total possible interactions', 'combinations', 'combination counts']\n",
    "element = \"missing interactions\"\n",
    "cc_results_t(\"Train 1\", coverage=train1_coverage, element=element, strengths=[1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization results: __demo__/rareplanes_demo/demo_1-coverage_train1/CC/\n",
    "visualize_cc(input_cc_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 2: Load, run, results\n",
    "input_cc_train2 = load_json(\n",
    "    os.path.join(\"rareplanes_demo\", \"configs\", \"cc_train2.json\")\n",
    ")\n",
    "display(input_cc_train2)\n",
    "# Note that the config_id and dataset fields have changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2_coverage = codex.run(input_cc_train2, verbose=\"1\")\n",
    "cc_results_t(\"Train 2\", train2_coverage, \"CC\", [1, 2, 3])\n",
    "visualize_cc(input_cc_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test12: Load, run, results\n",
    "input_cc_test12 = load_json(\n",
    "    os.path.join(\"rareplanes_demo\", \"configs\", \"cc_test12.json\")\n",
    ")\n",
    "test12_coverage = codex.run(input_cc_test12, verbose=\"1\")\n",
    "cc_results_t(\"Test12\", test12_coverage, \"CC\", [1, 2, 3])\n",
    "visualize_cc(input_cc_test12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset evaluation allows the user to test **how completely the dataset covers that input space.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c) Model performance and dataset evaluation\n",
    "Furthermore, depending on how the universe is defined, combinatorial coverage over the universe resulting from dataset evaluation can be correlated with model performance. If a universe describes the operating envelope poorly, CC is misleading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CC of training set vs. model performance\n",
    "# SELECT metric: [precision, recall, f1]\n",
    "metric = \"f1\"\n",
    "performance_train1 = model_performance(\n",
    "    \"train1\",\n",
    "    \"test12\",\n",
    "    input_cc_train1,\n",
    "    input_cc_test12,\n",
    "    train1_coverage,\n",
    "    test12_coverage,\n",
    "    metric=metric,\n",
    ")\n",
    "performance_train2 = model_performance(\n",
    "    \"train2\",\n",
    "    \"test12\",\n",
    "    input_cc_train2,\n",
    "    input_cc_test12,\n",
    "    train2_coverage,\n",
    "    test12_coverage,\n",
    "    metric=metric,\n",
    ")\n",
    "\n",
    "differential_performance_cc(\n",
    "    train1_coverage, train2_coverage, performance_train1, performance_train2, metric, 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this example with this particular defined universe, higher coverage over the universe is correlated with higher model performance. Depending on the formulation of the particular operating envelope, coverage can be a helpful metric of performance but also a helpful predictor of performance.\n",
    "\n",
    "This example demonstrates the capability of dataset evaluation. Dataset evaluation enables a user to characterize how complete a dataset is over a defined universe. In this case, the test set, as is the train2 set, is relatively complete over the defined universe. However, there likely exist scenarios in which the model operates in an environment that is unlike the complete universe. Because of this, there is a need to characterize the relationship between two sets of data that may have different envelopes, as can be the case when datasets are split into training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d) Try: Bin adjustment\n",
    "\n",
    "Navigating to 'rareplanes_demo/binning/bins-signif.txt', try re-adjusting a bins of continuous variables to reconstruct the universe and reeavluate the dataset.\n",
    "\n",
    "**Note: Bins should cover all values between the minimum and the maximum of each feature.** Run the following cells afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_binning_file(os.path.join(\"rareplanes_demo\", \"binning\", \"bins-edit.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cc_train1 = load_json(\n",
    "    os.path.join(\"rareplanes_demo\", \"configs\", \"cc_train1.json\")\n",
    ")\n",
    "input_cc_train1[\"bin_file\"] = \"binning/bins-edit.txt\"\n",
    "results_cc_train1 = codex.run(input_cc_train1, verbose=\"1\")\n",
    "cc_results_t(\"Train 1, bins readjusted:\", results_cc_train1, \"CC\", [1, 2, 3])\n",
    "visualize_cc(input_cc_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Dataset Split Evaluation\n",
    "\"Dataset split evaluation\" computes set difference combinatorial coverage (SDCC) between training, validation, and test datasets.\n",
    "\n",
    "*\"How do I characterize the difference and distance between training/validation/testing splits of my dataset?\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differing operating envelopes\n",
    "For simplicity, consider two completely separate regions, A and B, of the RarePlanes dataset. These regions might exist as the different operating envelopes environments a model is deployed in:\n",
    "- Region A was constructed by selecting samples containing the three 2-way interactions of level 1 of the Hour_of_Day metadata feature and levels 1, 2, and 3 of the avg_pan_resolution metadata feature.\n",
    "    - Samples containing h1\\*p1, h1\\*p2, h1\\*p3\n",
    "- Region B was constructed by selecting samples containing the three 2-way interactions of level 2 of the Hour_of_Day metadata feature and levels 1, 2, and 3 of the avg_pan_resolution metadata feature.\n",
    "    - Samples containing h2\\*p1, h2\\*p2, h2\\*p3\n",
    "- size(regionA) = size(regionB)\n",
    "\n",
    "Because of this construction, A and B are disjoint in 2-way interactions and therefore disjoint in samples at the 3-way interaction level as well as being disjoint in their samples.\n",
    "\n",
    "In each separate region, training and testing **splits** are constructed by random sampling.\n",
    "- trainA, testA is randomly sampled 85-15.\n",
    "- trainB, testB is randomly sampled 85-15."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset splits)\n",
    "Dataset splits are leveraged by CODEX in the form of split files to compute CC values of splits and SDCC values between splits. \n",
    "\n",
    "CODEX supports split files in specific JSON format to select samples for each split.\n",
    "- Lists under keys designating the sample names belonging to each split as they appear in the dataset ('train', 'validation', 'test')\n",
    "- Split ID for user record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_split_file(os.path.join(\"rareplanes_demo\", \"splits\", \"split_AB_combined.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and view splits of sample ID's provided in file\n",
    "splits_ab = load_json(\n",
    "    os.path.join(\"rareplanes_demo\", \"splits\", \"split_AB_combined.json\")\n",
    ")\n",
    "\n",
    "trainA_ids = splits_ab[\"trainA\"]\n",
    "testA_ids = splits_ab[\"testA\"]\n",
    "trainB_ids = splits_ab[\"trainB\"]\n",
    "testB_ids = splits_ab[\"testB\"]\n",
    "print(\"{} samples in train A: {}\".format(len(trainA_ids), trainA_ids[:2] + [\"...\"]))\n",
    "print(\"{} samples in test A: {}\".format(len(testA_ids), testA_ids[:2] + [\"...\"]))\n",
    "print(\"\")\n",
    "print(\"{} samples in train B: {}\".format(len(trainB_ids), trainB_ids[:2] + [\"...\"]))\n",
    "print(\"{} samples in test B: {}\".format(len(testB_ids), testB_ids[:2] + [\"...\"]))\n",
    "print(\"\")\n",
    "intersection = split_intersection(trainA_ids, testA_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a) Dataset Split Evaluation: Similar Operating Envelopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "rareplanes_df = pd.read_csv(\n",
    "    os.path.join(\n",
    "        \"rareplanes_demo\",\n",
    "        \"metadata\",\n",
    "        \"RarePlanes_Metadata_Augmented_Processed_localized-tiled-controlpt-d01-full_resampled.csv\",\n",
    "    )\n",
    ")\n",
    "display(rareplanes_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning file, binned dataset\n",
    "display_binning_file(os.path.join(\"rareplanes_demo\", \"binning\", \"bins-signif.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Universe and binned dataset\n",
    "input_sdcc_tAeA = load_json(os.path.join(\"rareplanes_demo\", \"configs\", \"sdcc_A-A.json\"))\n",
    "universe, rareplanes_df_binned = codex.universe_handler.define_input_space(\n",
    "    input_sdcc_tAeA\n",
    ")\n",
    "display(universe)\n",
    "display(rareplanes_df_binned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input files\n",
    "input_sdcc_tAeA = load_json(os.path.join(\"rareplanes_demo\", \"configs\", \"sdcc_A-A.json\"))\n",
    "display(input_sdcc_tAeA)\n",
    "input_sdcc_tBeB = load_json(os.path.join(\"rareplanes_demo\", \"configs\", \"sdcc_B-B.json\"))\n",
    "display(input_sdcc_tBeB)\n",
    "# Note changes to the fields: mode, config_id, split_folder, split_file, source_tag, target_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SDCC within region A\n",
    "results_sdcc_tAeA = codex.run(input_sdcc_tAeA, verbose=\"1\")\n",
    "\n",
    "# Train interactions not in test\n",
    "sdcc_results_t(\"A: train-test\", results_sdcc_tAeA, \"SDCC\", [1, 2, 3], \"trainA-testA\")\n",
    "# Test interactions not in train\n",
    "sdcc_results_t(\"A: test-train\", results_sdcc_tAeA, \"SDCC\", [1, 2, 3], \"testA-trainA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_sdcc(input_sdcc_tAeA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SDCC within region B\n",
    "results_sdcc_tBeB = codex.run(input_sdcc_tBeB, verbose=\"1\")\n",
    "\n",
    "# Train interactions not in test\n",
    "sdcc_results_t(\"B: train-test\", results_sdcc_tBeB, \"SDCC\", [1, 2, 3], \"trainB-testB\")\n",
    "# Test interactions not in train\n",
    "sdcc_results_t(\"B: test-train\", results_sdcc_tBeB, \"SDCC\", [1, 2, 3], \"testB-trainB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_sdcc(input_sdcc_tBeB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both region A and region B, every interaction appearing in the test set appears in the training set, and every interaction appearing in the trianing set appears in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b) Dataset Split Evaluation: Differing Operating Envelopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input files\n",
    "input_sdcc_tAeB = load_json(\n",
    "    os.path.join(\"rareplanes_demo\", \"configs\", \"sdcc_trnA-testB.json\")\n",
    ")\n",
    "input_sdcc_tBeA = load_json(\n",
    "    os.path.join(\"rareplanes_demo\", \"configs\", \"sdcc_trnB-testA.json\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset split comparison across regions\n",
    "results_sdcc_tAeB = codex.run(input_sdcc_tAeB, verbose=\"1\")\n",
    "\n",
    "# Train interactions not in test\n",
    "sdcc_results_t(\n",
    "    \"Train A, test B: train-test\", results_sdcc_tAeB, \"SDCC\", [1, 2, 3], \"trainA-testB\"\n",
    ")\n",
    "# Test interactions not in train\n",
    "sdcc_results_t(\n",
    "    \"Train A, test B: test-train\", results_sdcc_tAeB, \"SDCC\", [1, 2, 3], \"testB-trainA\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_sdcc(input_sdcc_tAeB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset split comparison across regions\n",
    "results_sdcc_tBeA = codex.run(input_sdcc_tBeA, verbose=\"1\")\n",
    "\n",
    "# Train interactions not in test\n",
    "sdcc_results_t(\n",
    "    \"Train B, test A: train-test\", results_sdcc_tBeA, \"SDCC\", [1, 2, 3], \"trainB-testA\"\n",
    ")\n",
    "# Test interactions not in train\n",
    "sdcc_results_t(\n",
    "    \"Train B, test A: test-train\", results_sdcc_tBeA, \"SDCC\", [1, 2, 3], \"testA-trainB\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_sdcc(input_sdcc_tBeA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c) Dataset split evaluation and model performance\n",
    "Assuming or knowing that the model performs well over the entire defined universe, SDCC that results from dataset split evaluation can be a predictor of how a model will perform given its difference from the operating envelope of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SDCC of training set vs. model performance\n",
    "# SELECT metric: [precision, recall, f1]\n",
    "metric = \"f1\"\n",
    "performance_trainAA = model_performance_sdcc(\n",
    "    \"testA\", \"trainA\", input_sdcc_tAeA, metric=metric\n",
    ")\n",
    "performance_trainAB = model_performance_sdcc(\n",
    "    \"testB\", \"trainA\", input_sdcc_tAeB, metric=metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"precision\"  # [precision, f1, recall]\n",
    "differential_performance_sdcc(\n",
    "    results_sdcc_tAeA,\n",
    "    results_sdcc_tAeB,\n",
    "    \"testA-trainA\",\n",
    "    \"testB-trainA\",\n",
    "    performance_trainAA,\n",
    "    performance_trainAB,\n",
    "    metric,\n",
    "    2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When deployed outside of its operating envelope, model performance degrades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Systematic Inclusion and Exclusion (SIE)\n",
    "\n",
    "The SIE experiment aims to discover important combinations of features by systematically withholding each interaction from training and comparing a model's performance on one test set also withholding the interaction and one that contains only samples with said interaction.\n",
    "\n",
    "*Beyond a feature-value level, what combinations of features and their interactions are most critical for the model to see in the dataset during training?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "rareplanes_df = pd.read_csv(\n",
    "    os.path.join(\n",
    "        \"rareplanes_demo\",\n",
    "        \"metadata\",\n",
    "        \"RarePlanes_Metadata_Augmented_Processed_localized-tiled-controlpt-d01-full_resampled.csv\",\n",
    "    )\n",
    ")\n",
    "display(rareplanes_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning file, binned dataset\n",
    "display_binning_file(os.path.join(\"rareplanes_demo\", \"binning\", \"bins-complete.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Universe and binned dataset\n",
    "input_sie = load_json(os.path.join(\"rareplanes_demo\", \"configs\", \"sie.json\"))\n",
    "universe, rareplanes_df_binned = codex.universe_handler.define_input_space(input_sie)\n",
    "display(rareplanes_df_binned.head())\n",
    "display(universe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sie = load_json(os.path.join(\"rareplanes_demo\", \"configs\", \"sie.json\"))\n",
    "results = codex.run(input_sie, verbose=\"1\")\n",
    "\n",
    "print(\"Results contents:\", list(results.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_sie_train_set(input_sie, \"Hour_of_Day\", \"[10.26,11.27)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_sie_test_sets(input_sie, \"Hour_of_Day\", \"[10.26,11.27)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations: SIE included/excluded training\n",
    "metric = \"precision\"  # [precision, recall, f1]\n",
    "display_sie_results(input_sie, metric=metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
