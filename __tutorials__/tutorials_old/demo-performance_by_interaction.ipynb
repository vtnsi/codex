{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install dependencies and ensure that Python version >= 3.10. Restart the Kernel if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import ipywidgets as widgets\n",
    "\n",
    "sys.path.append('..')\n",
    "import codex\n",
    "import src.output as output\n",
    "import tutorial_materials.build.tutorial_functions as tutorials\n",
    "\n",
    "with open('tutorial_materials/input/demo_input-performance_by_interaction_rp.json') as f:\n",
    "    codex_input = json.load(f)\n",
    "    output_path, strengths = codex.input_parser.define_experiment_variables(codex_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance by Interaction\n",
    "Performance by interaction simultaneously computes combinatorial coverage over a training set while aggregating the per-sample performance of samples possessing an interaction for each interaction in the data for each level of t specified.\n",
    "\n",
    "This experiment is to identify which interactions in the test set have samples that the model best performs on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider this example abstract dataset containing feature columns \"A\", \"B\", \"C\", \"D\" as well as a unique sample ID column and label column(s). Multiple strengths can be provided in one input file to obtain a set of $SDCC_t$ outputs as well as $CC_t$ outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input file\n",
    "\n",
    "The input file defines all the necessary components for the experiment configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tutorial_materials/input/demo_input-dataset_split_evaluation.json') as f:\n",
    "    codex_input = json.load(f)\n",
    "    output_path, strengths = codex.input_parser.define_experiment_variables(codex_input)\n",
    "\n",
    "display(codex_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the dataset and a binning file, a universe that describes the input space with all of its features and levels can be defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_full = pd.read_csv(os.path.join('tutorial_materials', 'datasets_tabular', 'abstract_native.csv')).drop('Unnamed: 0', axis=1)\n",
    "display(\"DATASET\", dataset_full.head())\n",
    "\n",
    "with open(os.path.join('tutorial_materials', 'binning', 'bins-abstract.txt')) as f:\n",
    "    print(\"BINNING SCHEME:\")\n",
    "    print(f.read())\n",
    "\n",
    "print(\"\\nSTRENGTHS:\")\n",
    "print(\"t =\",strengths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universe\n",
    "With the dataset and a binning file, a universe that describes the input space with all of its features and levels can be defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe, dataset, features = codex.codex_universe.define_input_space(codex_input)\n",
    "display(universe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and Performance\n",
    "\n",
    "Each sample of data from a dataset that a trained machine learning model operates on not only takes values for its features, but values for its interactions between features as well. Testing performance for combinations of features can hopefully shed light on how machine learning models perform beyond the surface level feature value pair. This requires per-sample performance, as each sample has a unique set of feature-value pairs for t-way strengths. Observe the format of the performance file with Per Sample Performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perf GEN\n",
    "split_dict, performance_dict, metric = codex.input_parser.extract_sp(codex_input)\n",
    "\n",
    "display(performance_dict)\n",
    "#output.output_json_readable(performance_dict, write_json=True, \n",
    "#                            file_path=os.path.join('tutorial_materials', 'performance', 'performance_0{}_ps.json'.format(0)))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Run\n",
    "\n",
    "With a dataset, values of t, a means of universe definition, and split and performance files, performance by interaction can be run. Note: Performance by interaction requires Per-Sample-Performance in the correct formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_full = codex.run(codex_input, subset='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_info = codex.output.results_parser.consolidated_interaction_info(results_full, strengths, metric, 'ascending descending', 5)\n",
    "#output.output_json_readable(interaction_info, print_json=True)\n",
    "print(\"Top performing interactions of training set, t=2:\", interaction_info[3]['top interactions'])\n",
    "print(\"Bottom performing interactions of training set, t=2:\", interaction_info[3]['bottom interactions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Results: Visualizations\n",
    "\n",
    "1) Performance and proportion frequency heatmaps\n",
    "\n",
    "The performance-based nature of this experiment calls the inclusion of new combinatorial plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Sorted high/low performing interactions.\n",
    "\n",
    "From the results of performance by interaction, we can identify and visualize the differences of top and bottom performing interactions for each strength t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(os.path.join(output_path, 'pxi_performing-t3.png'))\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Performance vs standardized counts pooportions\n",
    "\n",
    "Performance by interaction also includes an analysis of how interactions perform against their counts, or number of appearences across the samples in the training set. Counts are preserved in the results. The analysis included in this mode examines whether more frequent interactions in data perform better when training on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"COUNTS, t=3:\", results_full['3']['combination counts'])\n",
    "img = Image.open(os.path.join(output_path, 'pxi_performance_vs_freq-2.png'))\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Model Probing\n",
    "\n",
    "Due to the handy per-interaction basis of performance by interaction and describing performance based in the combinatorial space, this can be used for an additional experiment, the model probe. For red-teaming applications..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(os.path.join(output_path, 'dataset_split_comparison_2.png'))\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example on RarePlanes\n",
    "\n",
    "Dataset evaluation can be run on any dataset as long a tabular dataset, features to compute over are provided. This can be demonstrated on the RarePlanes dataset. \n",
    "\n",
    "Rareplanes is an open source dataset consisting of real and synthetic images. Concerning the real dataset, 253 satellite images exist as 8,525 tiles. Provided tabular metadata is included, and this is a case in which CODEX can be used to explore a dataset that itself is not tabular in its original form.\n",
    "\n",
    "Below is one such tile, along with its associated metadata. Both the original sample and its metadata are effectively tied.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rareplanes_df = pd.read_csv(os.path.join('tutorial_materials', 'datasets_tabular', 'RarePlanes_Metadata_Augmented_Processed_localized-tiled-controlpt.csv')).drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "rareplanes_df.index = rareplanes_df.image_tile_id\n",
    "\n",
    "img = Image.open(os.path.join('..', 'assets', '98_104001000F15D300_tile_177.png'))\n",
    "\n",
    "display(rareplanes_df.loc['98_104001000F15D300_tile_177'])\n",
    "display(rareplanes_df[rareplanes_df.index == '98_104001000F15D300_tile_177'])\n",
    "display(img)\n",
    "\n",
    "display(rareplanes_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codex_input['dataset_name'] = 'RarePlanes'\n",
    "codex_input['dataset_file'] = 'RarePlanes_Metadata_Augmented_Processed_localized-tiled-controlpt.csv'\n",
    "codex_input['features'] = ['Hour_of_Day', 'Season', 'avg_sun_elevation_angle', 'off_nadir_max', 'avg_pan_resolution', 'biome', 'CONTROL']\n",
    "codex_input['sample_id_column'] = 'image_tile_id'\n",
    "codex_input['bin_file'] = \"tutorial_materials/binning/bins-rareplanes_complete.txt\"\n",
    "results_rareplanes = codex.run(codex_input)\n",
    "#output.output_json_readable(codex_input, print_json=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency overage map for t=2 on Rareplanes is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(os.path.join(output_path, 'CC', 'CC_t2_RarePlanes_frequency_all.png'))\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset evaluation can be a useful mode to diagnose a dataset's overall coverage, and what interactions are present or deficient that would be a model's potential input space."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
